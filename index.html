<!DOCTYPE html><!--7xvLW0UL4a_RRstIDYFtp--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/chunks/8a80e7184ad3a13f.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/chunks/b1406117c3282712.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/cccc67329d566df5.js"/><script src="/_next/static/chunks/76c064224d953678.js" async=""></script><script src="/_next/static/chunks/f7e899cb2e440e35.js" async=""></script><script src="/_next/static/chunks/1718578c68d8b113.js" async=""></script><script src="/_next/static/chunks/turbopack-90ce6fb12b89bf27.js" async=""></script><script src="/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/_next/static/chunks/d2be314c3ece3fbe.js" async=""></script><script src="/_next/static/chunks/a624b468970d3cc4.js" async=""></script><script src="/_next/static/chunks/921d4336bf7f3963.js" async=""></script><script src="/_next/static/chunks/08151fe5d8ff984c.js" async=""></script><meta name="next-size-adjust" content=""/><title>RoboGenAI | Underwater Robotics &amp; AI for Marine Exploration</title><meta name="description" content="Integration of Generative AI and Vision Language Models in Underwater Robotic Systems for Marine Exploration and Monitoring"/><meta name="author" content="RoboGenAI Consortium"/><meta name="keywords" content="underwater robotics,generative AI,vision language models,marine exploration,ROV,autonomous systems"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="font-sans antialiased"><div hidden=""><!--$--><!--/$--></div><div class="flex min-h-[100dvh] flex-col"><nav class="sticky top-0 z-50 w-full border-b border-border/40 bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60"><div class="mx-auto max-w-7xl px-4 sm:px-6 lg:px-8"><div class="flex h-16 items-center justify-between"><a class="flex items-center gap-2" href="/"><div class="flex h-10 w-10 items-center justify-center rounded-lg bg-primary"><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" class="h-6 w-6 text-primary-foreground"><path d="M12 2v4m0 12v4M4.93 4.93l2.83 2.83m8.48 8.48l2.83 2.83M2 12h4m12 0h4M4.93 19.07l2.83-2.83m8.48-8.48l2.83-2.83"></path><circle cx="12" cy="12" r="3"></circle></svg></div><div class="flex flex-col"><span class="text-lg font-bold leading-none">RoboGenAI</span><span class="text-xs text-muted-foreground">Marine Robotics Research</span></div></a><div class="hidden md:flex md:items-center md:gap-1"><a class="rounded-md px-3 py-2 text-sm font-medium transition-colors hover:bg-accent hover:text-accent-foreground bg-accent text-accent-foreground" href="/">Home</a><a class="rounded-md px-3 py-2 text-sm font-medium transition-colors hover:bg-accent hover:text-accent-foreground text-foreground/80" href="/work-packages">Work Packages</a><a class="rounded-md px-3 py-2 text-sm font-medium transition-colors hover:bg-accent hover:text-accent-foreground text-foreground/80" href="/publications">Publications</a><a class="rounded-md px-3 py-2 text-sm font-medium transition-colors hover:bg-accent hover:text-accent-foreground text-foreground/80" href="/media">Media</a><a class="rounded-md px-3 py-2 text-sm font-medium transition-colors hover:bg-accent hover:text-accent-foreground text-foreground/80" href="/team">Team</a><a class="rounded-md px-3 py-2 text-sm font-medium transition-colors hover:bg-accent hover:text-accent-foreground text-foreground/80" href="/contact">Contact</a><div class="relative group"><button type="button" class="flex items-center gap-1 rounded-md px-3 py-2 text-sm font-medium text-foreground/80 transition-colors hover:bg-accent hover:text-accent-foreground">Results<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down h-4 w-4"><path d="m6 9 6 6 6-6"></path></svg></button><div class="pointer-events-none absolute left-0 top-full z-50 w-48 rounded-md border border-border/60 bg-background/95 p-1 opacity-0 shadow-lg transition group-hover:pointer-events-auto group-hover:opacity-100 group-focus-within:pointer-events-auto group-focus-within:opacity-100 before:absolute before:-top-2 before:left-0 before:h-2 before:w-full before:content-[&#x27;&#x27;]"><a href="https://github.com/robogenai" target="_blank" rel="noreferrer" class="block rounded-md px-3 py-2 text-sm text-foreground/80 transition hover:bg-accent hover:text-accent-foreground">GitHub</a><a href="https://sharepoint.com" target="_blank" rel="noreferrer" class="block rounded-md px-3 py-2 text-sm text-foreground/80 transition hover:bg-accent hover:text-accent-foreground">SharePoint</a></div></div></div><button data-slot="button" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 size-9 md:hidden"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu h-6 w-6"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg></button></div></div></nav><main class="flex-1"><section class="relative overflow-hidden border-b border-border/40" style="opacity:0;transform:translateY(24px)"><div class="absolute inset-0 bg-[linear-gradient(to_right,oklch(var(--border))_1px,transparent_1px),linear-gradient(to_bottom,oklch(var(--border))_1px,transparent_1px)] bg-[size:4rem_4rem] [mask-image:radial-gradient(ellipse_80%_50%_at_50%_0%,#000_70%,transparent_110%)]"></div><div class="relative mx-auto max-w-7xl px-4 py-24 sm:px-6 sm:py-32 lg:px-8"><div class="mx-auto max-w-3xl text-center"><div class="mb-8 inline-flex items-center gap-2 rounded-full border border-border bg-muted/50 px-4 py-2 text-sm"><span class="relative flex h-2 w-2"><span class="absolute inline-flex h-full w-full animate-ping rounded-full bg-accent opacity-75"></span><span class="relative inline-flex h-2 w-2 rounded-full bg-accent"></span></span>Project Period: 2025-2027</div><h1 class="mb-6 text-4xl font-bold tracking-tight text-balance sm:text-6xl">Underwater Robotics Meets <span class="text-primary">Generative AI</span></h1><p class="mb-10 text-lg text-muted-foreground leading-relaxed text-balance">Integrating Vision Language Models and Generative AI in autonomous underwater vehicles for advanced marine exploration and monitoring.</p><div class="flex flex-wrap items-center justify-center gap-4"><a data-slot="button" class="inline-flex items-center justify-center gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-primary text-primary-foreground hover:bg-primary/90 h-10 rounded-md px-6 has-[&gt;svg]:px-4" href="/work-packages">Explore Work Packages<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right ml-2 h-4 w-4"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg></a><a data-slot="button" class="inline-flex items-center justify-center gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 h-10 rounded-md px-6 has-[&gt;svg]:px-4" href="/publications">View Publications</a></div></div></div></section><section class="border-b border-border/40 py-8 sm:py-16" style="opacity:0;transform:translateY(24px)"><div class="mx-auto max-w-7xl px-4 sm:px-6 lg:px-8"><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm w-full border-border/50"><div data-slot="card-content" class="p-8 sm:p-10"><div class="max-w-3xl"><h2 class="mb-3 text-3xl font-bold tracking-tight sm:text-4xl text-balance">Next-Generation Underwater Robotic System</h2><p class="text-lg text-muted-foreground leading-relaxed text-balance">Integrating Generative AI and Vision-Language Models (VLMs) for intelligent, context-aware marine exploration and monitoring.</p></div><div class="mt-10 grid gap-6 md:grid-cols-[1.3fr_1fr_1fr]"><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm min-w-0 border-border/50"><div class="overflow-hidden rounded-t-lg bg-muted"><img alt="Abstract marine robotics concept" loading="lazy" width="640" height="240" decoding="async" data-nimg="1" class="h-24 w-full object-cover" style="color:transparent" src="/placeholder.svg"/></div><div data-slot="card-content" class="p-5"><h3 class="mb-3 text-lg font-semibold">What</h3><ul class="list-disc space-y-2 pl-4 text-sm text-muted-foreground"><li>Deploy coordinated teams of autonomous underwater vehicles (AUVs) capable of efficiently surveying large areas.</li><li>Combine visual, chemical, and acoustic sensing to generate high-resolution 3D maps of underwater environments.</li><li>Use these 3D reconstructions to build digital twins that enable long-term monitoring, simulation, and predictive modeling.</li><li>Develop underwater-adapted vision-language models that can interpret video, describe scenes, answer questions, detect anomalies, and support ecological insights.</li><li>Enable real-time detection of pollution events, ecological changes, hazards, and structural degradation.</li><li>Improve underwater communication through integrated acoustic and optical links.</li><li>Ensure continuous, energy-aware operation via optimized navigation, cooperative behaviors, and distributed recharging.</li></ul></div></div><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm min-w-0 border-border/50"><div class="overflow-hidden rounded-t-lg bg-muted"><img alt="Underwater research motivation" loading="lazy" width="640" height="240" decoding="async" data-nimg="1" class="h-24 w-full object-cover" style="color:transparent" src="/placeholder.svg"/></div><div data-slot="card-content" class="p-5"><h3 class="mb-3 text-lg font-semibold">Why</h3><ul class="list-disc space-y-2 pl-4 text-sm text-muted-foreground"><li>Underwater environments are complex, data-rich, and difficult to interpret in real-time.</li><li>There is a growing need for autonomous, AI-enabled robotic systems to perform long-term monitoring and environmental analysis.</li><li>Generative AI can summarize, interpret, and visualize underwater sensor data efficiently.</li><li>The project supports UAE’s innovation goals in marine technology and sustainable ocean monitoring.</li></ul></div></div><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm min-w-0 border-border/50"><div class="overflow-hidden rounded-t-lg bg-muted"><img alt="Workflow for underwater AI systems" loading="lazy" width="640" height="240" decoding="async" data-nimg="1" class="h-24 w-full object-cover" style="color:transparent" src="/placeholder.svg"/></div><div data-slot="card-content" class="p-5"><h3 class="mb-3 text-lg font-semibold">How</h3><ul class="list-disc space-y-2 pl-4 text-sm text-muted-foreground"><li>Develop customized ROVs with multi-sensor capabilities.</li><li>Train Vision-Language Models (VLMs) for underwater perception.</li><li>Enable robotic swarms for wide-area coverage and cooperative decision-making.</li><li>Build multi-modal analytics for underwater data integration and interpretation.</li><li>Validate through simulation, lab, and real-world testing.</li></ul></div></div></div></div></div></div></section><section class="border-b border-border/40 py-12 sm:py-16" style="opacity:0;transform:translateY(24px)"><div class="mx-auto max-w-7xl px-4 sm:px-6 lg:px-8"><div class="mb-12 text-center"><h2 class="mb-4 text-3xl font-bold tracking-tight sm:text-4xl text-balance">Advancing Marine Robotics</h2><p class="mx-auto max-w-2xl text-lg text-muted-foreground text-balance">Five integrated work packages combining cutting-edge AI with underwater robotics</p></div><div class="grid gap-8 md:grid-cols-2 lg:grid-cols-3"><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm border-border/50 transition-shadow hover:shadow-lg"><div data-slot="card-content" class="p-6"><div class="mb-4 flex h-12 w-12 items-center justify-center rounded-lg bg-primary/10"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-waves h-6 w-6 text-primary"><path d="M2 6c.6.5 1.2 1 2.5 1C7 7 7 5 9.5 5c2.6 0 2.4 2 5 2 2.5 0 2.5-2 5-2 1.3 0 1.9.5 2.5 1"></path><path d="M2 12c.6.5 1.2 1 2.5 1 2.5 0 2.5-2 5-2 2.6 0 2.4 2 5 2 2.5 0 2.5-2 5-2 1.3 0 1.9.5 2.5 1"></path><path d="M2 18c.6.5 1.2 1 2.5 1 2.5 0 2.5-2 5-2 2.6 0 2.4 2 5 2 2.5 0 2.5-2 5-2 1.3 0 1.9.5 2.5 1"></path></svg></div><h3 class="mb-2 text-xl font-semibold">WP1: ROV Development</h3><p class="text-sm text-muted-foreground leading-relaxed">Advanced underwater vehicles equipped with sensors, cameras, and communication systems designed for AI integration.</p></div></div><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm border-border/50 transition-shadow hover:shadow-lg"><div data-slot="card-content" class="p-6"><div class="mb-4 flex h-12 w-12 items-center justify-center rounded-lg bg-secondary/10"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-brain h-6 w-6 text-secondary"><path d="M12 5a3 3 0 1 0-5.997.125 4 4 0 0 0-2.526 5.77 4 4 0 0 0 .556 6.588A4 4 0 1 0 12 18Z"></path><path d="M12 5a3 3 0 1 1 5.997.125 4 4 0 0 1 2.526 5.77 4 4 0 0 1-.556 6.588A4 4 0 1 1 12 18Z"></path><path d="M15 13a4.5 4.5 0 0 1-3-4 4.5 4.5 0 0 1-3 4"></path><path d="M17.599 6.5a3 3 0 0 0 .399-1.375"></path><path d="M6.003 5.125A3 3 0 0 0 6.401 6.5"></path><path d="M3.477 10.896a4 4 0 0 1 .585-.396"></path><path d="M19.938 10.5a4 4 0 0 1 .585.396"></path><path d="M6 18a4 4 0 0 1-1.967-.516"></path><path d="M19.967 17.484A4 4 0 0 1 18 18"></path></svg></div><h3 class="mb-2 text-xl font-semibold">Vision Language Models</h3><p class="text-sm text-muted-foreground leading-relaxed">3D mapping, visual question answering, and image captioning systems for intelligent underwater perception.</p></div></div><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm border-border/50 transition-shadow hover:shadow-lg"><div data-slot="card-content" class="p-6"><div class="mb-4 flex h-12 w-12 items-center justify-center rounded-lg bg-accent/10"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-network h-6 w-6 text-accent"><rect x="16" y="16" width="6" height="6" rx="1"></rect><rect x="2" y="16" width="6" height="6" rx="1"></rect><rect x="9" y="2" width="6" height="6" rx="1"></rect><path d="M5 16v-3a1 1 0 0 1 1-1h12a1 1 0 0 1 1 1v3"></path><path d="M12 12V8"></path></svg></div><h3 class="mb-2 text-xl font-semibold">Multi-Robot Coordination</h3><p class="text-sm text-muted-foreground leading-relaxed">Decision-making algorithms for coordinating multiple AUVs in complex marine environments.</p></div></div><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm border-border/50 transition-shadow hover:shadow-lg"><div data-slot="card-content" class="p-6"><div class="mb-4 flex h-12 w-12 items-center justify-center rounded-lg bg-chart-2/10"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-microscope h-6 w-6 text-chart-2"><path d="M6 18h8"></path><path d="M3 22h18"></path><path d="M14 22a7 7 0 1 0 0-14h-1"></path><path d="M9 14h2"></path><path d="M9 12a2 2 0 0 1-2-2V6h6v4a2 2 0 0 1-2 2Z"></path><path d="M12 6V3a1 1 0 0 0-1-1H9a1 1 0 0 0-1 1v3"></path></svg></div><h3 class="mb-2 text-xl font-semibold">Testing &amp; Validation</h3><p class="text-sm text-muted-foreground leading-relaxed">Comprehensive validation from simulation to real-world marine scenarios ensuring robust performance.</p></div></div><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm border-border/50 transition-shadow hover:shadow-lg"><div data-slot="card-content" class="p-6"><div class="mb-4 flex h-12 w-12 items-center justify-center rounded-lg bg-chart-3/10"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-database h-6 w-6 text-chart-3"><ellipse cx="12" cy="5" rx="9" ry="3"></ellipse><path d="M3 5V19A9 3 0 0 0 21 19V5"></path><path d="M3 12A9 3 0 0 0 21 12"></path></svg></div><h3 class="mb-2 text-xl font-semibold">Open Research</h3><p class="text-sm text-muted-foreground leading-relaxed">Publishing findings, presenting at conferences, and engaging with the scientific community.</p></div></div><div data-slot="card" class="text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm border-border/50 bg-accent/15 transition-shadow hover:shadow-lg"><div data-slot="card-content" class="p-6"><h3 class="mb-2 text-xl font-semibold">Explore More</h3><p class="mb-4 text-sm text-muted-foreground leading-relaxed">Discover detailed information about each work package, timeline, and research outputs.</p><a data-slot="button" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 h-8 rounded-md gap-1.5 px-3 has-[&gt;svg]:px-2.5" href="/work-packages">View All Work Packages<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right ml-2 h-4 w-4"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg></a></div></div></div></div></section><section class="py-12 sm:py-16" style="opacity:0;transform:translateY(24px)"><div class="mx-auto max-w-7xl px-4 sm:px-6 lg:px-8"><div class="mx-auto max-w-2xl text-center"><h2 class="mb-4 text-3xl font-bold tracking-tight sm:text-4xl text-balance">Join Our Research Journey</h2><p class="mb-8 text-lg text-muted-foreground text-balance">Stay updated on our progress, publications, and opportunities for collaboration in underwater AI robotics.</p><a data-slot="button" class="inline-flex items-center justify-center gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-primary text-primary-foreground hover:bg-primary/90 h-10 rounded-md px-6 has-[&gt;svg]:px-4" href="/contact">Get in Touch</a></div></div></section></main><footer class="border-t border-border/40 bg-muted/30"><div class="mx-auto max-w-7xl px-4 py-12 sm:px-6 lg:px-8"><div class="grid gap-8 md:grid-cols-3"><div><h3 class="mb-4 text-sm font-semibold uppercase tracking-wider">About RoboGenAI</h3><p class="text-sm text-muted-foreground leading-relaxed">Advancing underwater robotics through the integration of Generative AI and Vision Language Models for marine exploration and monitoring.</p></div><div><h3 class="mb-4 text-sm font-semibold uppercase tracking-wider">Quick Links</h3><ul class="space-y-2 text-sm"><li><a class="text-muted-foreground transition-colors hover:text-foreground" href="/work-packages">Work Packages</a></li><li><a class="text-muted-foreground transition-colors hover:text-foreground" href="/publications">Publications</a></li><li><a class="text-muted-foreground transition-colors hover:text-foreground" href="/team">Team</a></li><li><a class="text-muted-foreground transition-colors hover:text-foreground" href="/contact">Contact</a></li></ul></div><div><h3 class="mb-4 text-sm font-semibold uppercase tracking-wider">Connect</h3><div class="flex gap-4"><a href="mailto:contact@robogenai.eu" class="text-muted-foreground transition-colors hover:text-foreground" aria-label="Email"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mail h-5 w-5"><rect width="20" height="16" x="2" y="4" rx="2"></rect><path d="m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7"></path></svg></a><a href="https://linkedin.com/company/robogenai" class="text-muted-foreground transition-colors hover:text-foreground" aria-label="LinkedIn" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-linkedin h-5 w-5"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect width="4" height="12" x="2" y="9"></rect><circle cx="4" cy="4" r="2"></circle></svg></a><a href="https://github.com/robogenai" class="text-muted-foreground transition-colors hover:text-foreground" aria-label="GitHub" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-5 w-5"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a></div><p class="mt-4 text-xs text-muted-foreground">Funded by the European Commission</p></div></div><div class="mt-8 border-t border-border/40 pt-8"><p class="text-center text-xs text-muted-foreground">© <!-- -->2026<!-- --> RoboGenAI Consortium. All rights reserved.</p></div></div></footer></div><!--$--><!--/$--><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--><script src="/_next/static/chunks/cccc67329d566df5.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[39756,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/d2be314c3ece3fbe.js\"],\"default\"]\n3:I[37457,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/d2be314c3ece3fbe.js\"],\"default\"]\n4:I[2355,[\"/_next/static/chunks/a624b468970d3cc4.js\"],\"Analytics\"]\n5:I[13474,[\"/_next/static/chunks/a624b468970d3cc4.js\",\"/_next/static/chunks/921d4336bf7f3963.js\",\"/_next/static/chunks/08151fe5d8ff984c.js\"],\"Navigation\"]\n6:I[14950,[\"/_next/static/chunks/a624b468970d3cc4.js\",\"/_next/static/chunks/921d4336bf7f3963.js\",\"/_next/static/chunks/08151fe5d8ff984c.js\"],\"ScrollReveal\"]\n7:I[22016,[\"/_next/static/chunks/a624b468970d3cc4.js\",\"/_next/static/chunks/921d4336bf7f3963.js\",\"/_next/static/chunks/08151fe5d8ff984c.js\"],\"\"]\n11:I[68027,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/d2be314c3ece3fbe.js\"],\"default\"]\n:HL[\"/_next/static/chunks/8a80e7184ad3a13f.css\",\"style\"]\n:HL[\"/_next/static/chunks/b1406117c3282712.css\",\"style\"]\n:HL[\"/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"7xvLW0UL4a_RRstIDYFtp\",\"c\":[\"\",\"\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/8a80e7184ad3a13f.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/b1406117c3282712.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/a624b468970d3cc4.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"font-sans antialiased\",\"children\":[[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"$L4\",null,{}]]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"flex min-h-[100dvh] flex-col\",\"children\":[[\"$\",\"$L5\",null,{}],[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"$L6\",null,{\"className\":\"relative overflow-hidden border-b border-border/40\",\"children\":[[\"$\",\"div\",null,{\"className\":\"absolute inset-0 bg-[linear-gradient(to_right,oklch(var(--border))_1px,transparent_1px),linear-gradient(to_bottom,oklch(var(--border))_1px,transparent_1px)] bg-[size:4rem_4rem] [mask-image:radial-gradient(ellipse_80%_50%_at_50%_0%,#000_70%,transparent_110%)]\"}],[\"$\",\"div\",null,{\"className\":\"relative mx-auto max-w-7xl px-4 py-24 sm:px-6 sm:py-32 lg:px-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-3xl text-center\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-8 inline-flex items-center gap-2 rounded-full border border-border bg-muted/50 px-4 py-2 text-sm\",\"children\":[[\"$\",\"span\",null,{\"className\":\"relative flex h-2 w-2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"absolute inline-flex h-full w-full animate-ping rounded-full bg-accent opacity-75\"}],[\"$\",\"span\",null,{\"className\":\"relative inline-flex h-2 w-2 rounded-full bg-accent\"}]]}],\"Project Period: 2025-2027\"]}],[\"$\",\"h1\",null,{\"className\":\"mb-6 text-4xl font-bold tracking-tight text-balance sm:text-6xl\",\"children\":[\"Underwater Robotics Meets \",[\"$\",\"span\",null,{\"className\":\"text-primary\",\"children\":\"Generative AI\"}]]}],[\"$\",\"p\",null,{\"className\":\"mb-10 text-lg text-muted-foreground leading-relaxed text-balance\",\"children\":\"Integrating Vision Language Models and Generative AI in autonomous underwater vehicles for advanced marine exploration and monitoring.\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center justify-center gap-4\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"/work-packages\",\"children\":[\"Explore Work Packages\",[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-arrow-right ml-2 h-4 w-4\",\"children\":[[\"$\",\"path\",\"1ays0h\",{\"d\":\"M5 12h14\"}],[\"$\",\"path\",\"xquz4c\",{\"d\":\"m12 5 7 7-7 7\"}],\"$undefined\"]}]],\"data-slot\":\"button\",\"className\":\"inline-flex items-center justify-center gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [\u0026_svg]:pointer-events-none [\u0026_svg:not([class*='size-'])]:size-4 shrink-0 [\u0026_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-primary text-primary-foreground hover:bg-primary/90 h-10 rounded-md px-6 has-[\u003esvg]:px-4\",\"ref\":null}],\"$L8\"]}]]}]}]]}],\"$L9\",\"$La\",\"$Lb\"]}],\"$Lc\"]}],[\"$Ld\",\"$Le\"],\"$Lf\"]}],{},null,false,false]},null,false,false],\"$L10\",false]],\"m\":\"$undefined\",\"G\":[\"$11\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"12:I[85437,[\"/_next/static/chunks/a624b468970d3cc4.js\",\"/_next/static/chunks/921d4336bf7f3963.js\",\"/_next/static/chunks/08151fe5d8ff984c.js\"],\"Image\"]\n1f:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/d2be314c3ece3fbe.js\"],\"OutletBoundary\"]\n20:\"$Sreact.suspense\"\n22:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/d2be314c3ece3fbe.js\"],\"ViewportBoundary\"]\n24:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/d2be314c3ece3fbe.js\"],\"MetadataBoundary\"]\n8:[\"$\",\"$L7\",null,{\"href\":\"/publications\",\"children\":\"View Publications\",\"data-slot\":\"button\",\"className\":\"inline-flex items-center justify-center gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [\u0026_svg]:pointer-events-none [\u0026_svg:not([class*='size-'])]:size-4 shrink-0 [\u0026_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 h-10 rounded-md px-6 has-[\u003esvg]:px-4\",\"ref\":null}]\n"])</script><script>self.__next_f.push([1,"9:[\"$\",\"$L6\",null,{\"className\":\"border-b border-border/40 py-8 sm:py-16\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-7xl px-4 sm:px-6 lg:px-8\",\"children\":[\"$\",\"div\",null,{\"data-slot\":\"card\",\"className\":\"bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm w-full border-border/50\",\"children\":[\"$\",\"div\",null,{\"data-slot\":\"card-content\",\"className\":\"p-8 sm:p-10\",\"children\":[[\"$\",\"div\",null,{\"className\":\"max-w-3xl\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"mb-3 text-3xl font-bold tracking-tight sm:text-4xl text-balance\",\"children\":\"Next-Generation Underwater Robotic System\"}],[\"$\",\"p\",null,{\"className\":\"text-lg text-muted-foreground leading-relaxed text-balance\",\"children\":\"Integrating Generative AI and Vision-Language Models (VLMs) for intelligent, context-aware marine exploration and monitoring.\"}]]}],[\"$\",\"div\",null,{\"className\":\"mt-10 grid gap-6 md:grid-cols-[1.3fr_1fr_1fr]\",\"children\":[[\"$\",\"div\",null,{\"data-slot\":\"card\",\"className\":\"bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm min-w-0 border-border/50\",\"children\":[[\"$\",\"div\",null,{\"className\":\"overflow-hidden rounded-t-lg bg-muted\",\"children\":[\"$\",\"$L12\",null,{\"src\":\"/placeholder.svg\",\"alt\":\"Abstract marine robotics concept\",\"width\":640,\"height\":240,\"className\":\"h-24 w-full object-cover\"}]}],[\"$\",\"div\",null,{\"data-slot\":\"card-content\",\"className\":\"p-5\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"mb-3 text-lg font-semibold\",\"children\":\"What\"}],[\"$\",\"ul\",null,{\"className\":\"list-disc space-y-2 pl-4 text-sm text-muted-foreground\",\"children\":[[\"$\",\"li\",null,{\"children\":\"Deploy coordinated teams of autonomous underwater vehicles (AUVs) capable of efficiently surveying large areas.\"}],[\"$\",\"li\",null,{\"children\":\"Combine visual, chemical, and acoustic sensing to generate high-resolution 3D maps of underwater environments.\"}],[\"$\",\"li\",null,{\"children\":\"Use these 3D reconstructions to build digital twins that enable long-term monitoring, simulation, and predictive modeling.\"}],[\"$\",\"li\",null,{\"children\":\"Develop underwater-adapted vision-language models that can interpret video, describe scenes, answer questions, detect anomalies, and support ecological insights.\"}],[\"$\",\"li\",null,{\"children\":\"Enable real-time detection of pollution events, ecological changes, hazards, and structural degradation.\"}],[\"$\",\"li\",null,{\"children\":\"Improve underwater communication through integrated acoustic and optical links.\"}],[\"$\",\"li\",null,{\"children\":\"Ensure continuous, energy-aware operation via optimized navigation, cooperative behaviors, and distributed recharging.\"}]]}]]}]]}],[\"$\",\"div\",null,{\"data-slot\":\"card\",\"className\":\"bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm min-w-0 border-border/50\",\"children\":[[\"$\",\"div\",null,{\"className\":\"overflow-hidden rounded-t-lg bg-muted\",\"children\":[\"$\",\"$L12\",null,{\"src\":\"/placeholder.svg\",\"alt\":\"Underwater research motivation\",\"width\":640,\"height\":240,\"className\":\"h-24 w-full object-cover\"}]}],[\"$\",\"div\",null,{\"data-slot\":\"card-content\",\"className\":\"p-5\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"mb-3 text-lg font-semibold\",\"children\":\"Why\"}],[\"$\",\"ul\",null,{\"className\":\"list-disc space-y-2 pl-4 text-sm text-muted-foreground\",\"children\":[[\"$\",\"li\",null,{\"children\":\"Underwater environments are complex, data-rich, and difficult to interpret in real-time.\"}],[\"$\",\"li\",null,{\"children\":\"There is a growing need for autonomous, AI-enabled robotic systems to perform long-term monitoring and environmental analysis.\"}],[\"$\",\"li\",null,{\"children\":\"Generative AI can summarize, interpret, and visualize underwater sensor data efficiently.\"}],[\"$\",\"li\",null,{\"children\":\"The project supports UAE’s innovation goals in marine technology and sustainable ocean monitoring.\"}]]}]]}]]}],[\"$\",\"div\",null,{\"data-slot\":\"card\",\"className\":\"bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm min-w-0 border-border/50\",\"children\":[\"$L13\",\"$L14\"]}]]}]]}]}]}]}]\n"])</script><script>self.__next_f.push([1,"a:[\"$\",\"$L6\",null,{\"className\":\"border-b border-border/40 py-12 sm:py-16\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-7xl px-4 sm:px-6 lg:px-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-12 text-center\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"mb-4 text-3xl font-bold tracking-tight sm:text-4xl text-balance\",\"children\":\"Advancing Marine Robotics\"}],[\"$\",\"p\",null,{\"className\":\"mx-auto max-w-2xl text-lg text-muted-foreground text-balance\",\"children\":\"Five integrated work packages combining cutting-edge AI with underwater robotics\"}]]}],[\"$\",\"div\",null,{\"className\":\"grid gap-8 md:grid-cols-2 lg:grid-cols-3\",\"children\":[[\"$\",\"div\",null,{\"data-slot\":\"card\",\"className\":\"bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm border-border/50 transition-shadow hover:shadow-lg\",\"children\":[\"$\",\"div\",null,{\"data-slot\":\"card-content\",\"className\":\"p-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-4 flex h-12 w-12 items-center justify-center rounded-lg bg-primary/10\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-waves h-6 w-6 text-primary\",\"children\":[[\"$\",\"path\",\"knzxuh\",{\"d\":\"M2 6c.6.5 1.2 1 2.5 1C7 7 7 5 9.5 5c2.6 0 2.4 2 5 2 2.5 0 2.5-2 5-2 1.3 0 1.9.5 2.5 1\"}],[\"$\",\"path\",\"2jd2cc\",{\"d\":\"M2 12c.6.5 1.2 1 2.5 1 2.5 0 2.5-2 5-2 2.6 0 2.4 2 5 2 2.5 0 2.5-2 5-2 1.3 0 1.9.5 2.5 1\"}],[\"$\",\"path\",\"rd2r6e\",{\"d\":\"M2 18c.6.5 1.2 1 2.5 1 2.5 0 2.5-2 5-2 2.6 0 2.4 2 5 2 2.5 0 2.5-2 5-2 1.3 0 1.9.5 2.5 1\"}],\"$undefined\"]}]}],[\"$\",\"h3\",null,{\"className\":\"mb-2 text-xl font-semibold\",\"children\":\"WP1: ROV Development\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground leading-relaxed\",\"children\":\"Advanced underwater vehicles equipped with sensors, cameras, and communication systems designed for AI integration.\"}]]}]}],[\"$\",\"div\",null,{\"data-slot\":\"card\",\"className\":\"bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm border-border/50 transition-shadow hover:shadow-lg\",\"children\":[\"$\",\"div\",null,{\"data-slot\":\"card-content\",\"className\":\"p-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-4 flex h-12 w-12 items-center justify-center rounded-lg bg-secondary/10\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-brain h-6 w-6 text-secondary\",\"children\":[[\"$\",\"path\",\"l5xja\",{\"d\":\"M12 5a3 3 0 1 0-5.997.125 4 4 0 0 0-2.526 5.77 4 4 0 0 0 .556 6.588A4 4 0 1 0 12 18Z\"}],[\"$\",\"path\",\"ep3f8r\",{\"d\":\"M12 5a3 3 0 1 1 5.997.125 4 4 0 0 1 2.526 5.77 4 4 0 0 1-.556 6.588A4 4 0 1 1 12 18Z\"}],[\"$\",\"path\",\"1p4c4q\",{\"d\":\"M15 13a4.5 4.5 0 0 1-3-4 4.5 4.5 0 0 1-3 4\"}],[\"$\",\"path\",\"tmeiqw\",{\"d\":\"M17.599 6.5a3 3 0 0 0 .399-1.375\"}],[\"$\",\"path\",\"105sqy\",{\"d\":\"M6.003 5.125A3 3 0 0 0 6.401 6.5\"}],[\"$\",\"path\",\"ql3yin\",{\"d\":\"M3.477 10.896a4 4 0 0 1 .585-.396\"}],[\"$\",\"path\",\"1qfode\",{\"d\":\"M19.938 10.5a4 4 0 0 1 .585.396\"}],[\"$\",\"path\",\"2e4loj\",{\"d\":\"M6 18a4 4 0 0 1-1.967-.516\"}],[\"$\",\"path\",\"159ez6\",{\"d\":\"M19.967 17.484A4 4 0 0 1 18 18\"}],\"$undefined\"]}]}],[\"$\",\"h3\",null,{\"className\":\"mb-2 text-xl font-semibold\",\"children\":\"Vision Language Models\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground leading-relaxed\",\"children\":\"3D mapping, visual question answering, and image captioning systems for intelligent underwater perception.\"}]]}]}],[\"$\",\"div\",null,{\"data-slot\":\"card\",\"className\":\"bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm border-border/50 transition-shadow hover:shadow-lg\",\"children\":[\"$\",\"div\",null,{\"data-slot\":\"card-content\",\"className\":\"p-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-4 flex h-12 w-12 items-center justify-center rounded-lg bg-accent/10\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-network h-6 w-6 text-accent\",\"children\":[\"$L15\",\"$L16\",\"$L17\",\"$L18\",\"$L19\",\"$undefined\"]}]}],\"$L1a\",\"$L1b\"]}]}],\"$L1c\",\"$L1d\",\"$L1e\"]}]]}]}]\n"])</script><script>self.__next_f.push([1,"b:[\"$\",\"$L6\",null,{\"className\":\"py-12 sm:py-16\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-7xl px-4 sm:px-6 lg:px-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-2xl text-center\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"mb-4 text-3xl font-bold tracking-tight sm:text-4xl text-balance\",\"children\":\"Join Our Research Journey\"}],[\"$\",\"p\",null,{\"className\":\"mb-8 text-lg text-muted-foreground text-balance\",\"children\":\"Stay updated on our progress, publications, and opportunities for collaboration in underwater AI robotics.\"}],[\"$\",\"$L7\",null,{\"href\":\"/contact\",\"children\":\"Get in Touch\",\"data-slot\":\"button\",\"className\":\"inline-flex items-center justify-center gap-2 whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [\u0026_svg]:pointer-events-none [\u0026_svg:not([class*='size-'])]:size-4 shrink-0 [\u0026_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-primary text-primary-foreground hover:bg-primary/90 h-10 rounded-md px-6 has-[\u003esvg]:px-4\",\"ref\":null}]]}]}]}]\n"])</script><script>self.__next_f.push([1,"c:[\"$\",\"footer\",null,{\"className\":\"border-t border-border/40 bg-muted/30\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-7xl px-4 py-12 sm:px-6 lg:px-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"grid gap-8 md:grid-cols-3\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"mb-4 text-sm font-semibold uppercase tracking-wider\",\"children\":\"About RoboGenAI\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground leading-relaxed\",\"children\":\"Advancing underwater robotics through the integration of Generative AI and Vision Language Models for marine exploration and monitoring.\"}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"mb-4 text-sm font-semibold uppercase tracking-wider\",\"children\":\"Quick Links\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-2 text-sm\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$L7\",null,{\"href\":\"/work-packages\",\"className\":\"text-muted-foreground transition-colors hover:text-foreground\",\"children\":\"Work Packages\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L7\",null,{\"href\":\"/publications\",\"className\":\"text-muted-foreground transition-colors hover:text-foreground\",\"children\":\"Publications\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L7\",null,{\"href\":\"/team\",\"className\":\"text-muted-foreground transition-colors hover:text-foreground\",\"children\":\"Team\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L7\",null,{\"href\":\"/contact\",\"className\":\"text-muted-foreground transition-colors hover:text-foreground\",\"children\":\"Contact\"}]}]]}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"mb-4 text-sm font-semibold uppercase tracking-wider\",\"children\":\"Connect\"}],[\"$\",\"div\",null,{\"className\":\"flex gap-4\",\"children\":[[\"$\",\"a\",null,{\"href\":\"mailto:contact@robogenai.eu\",\"className\":\"text-muted-foreground transition-colors hover:text-foreground\",\"aria-label\":\"Email\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-mail h-5 w-5\",\"children\":[[\"$\",\"rect\",\"18n3k1\",{\"width\":\"20\",\"height\":\"16\",\"x\":\"2\",\"y\":\"4\",\"rx\":\"2\"}],[\"$\",\"path\",\"1ocrg3\",{\"d\":\"m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7\"}],\"$undefined\"]}]}],[\"$\",\"a\",null,{\"href\":\"https://linkedin.com/company/robogenai\",\"className\":\"text-muted-foreground transition-colors hover:text-foreground\",\"aria-label\":\"LinkedIn\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-linkedin h-5 w-5\",\"children\":[[\"$\",\"path\",\"c2jq9f\",{\"d\":\"M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z\"}],[\"$\",\"rect\",\"mk3on5\",{\"width\":\"4\",\"height\":\"12\",\"x\":\"2\",\"y\":\"9\"}],[\"$\",\"circle\",\"bt5ra8\",{\"cx\":\"4\",\"cy\":\"4\",\"r\":\"2\"}],\"$undefined\"]}]}],[\"$\",\"a\",null,{\"href\":\"https://github.com/robogenai\",\"className\":\"text-muted-foreground transition-colors hover:text-foreground\",\"aria-label\":\"GitHub\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-github h-5 w-5\",\"children\":[[\"$\",\"path\",\"tonef\",{\"d\":\"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4\"}],[\"$\",\"path\",\"9comsn\",{\"d\":\"M9 18c-4.51 2-5-2-7-2\"}],\"$undefined\"]}]}]]}],[\"$\",\"p\",null,{\"className\":\"mt-4 text-xs text-muted-foreground\",\"children\":\"Funded by the European Commission\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-8 border-t border-border/40 pt-8\",\"children\":[\"$\",\"p\",null,{\"className\":\"text-center text-xs text-muted-foreground\",\"children\":[\"© \",2026,\" RoboGenAI Consortium. All rights reserved.\"]}]}]]}]}]\n"])</script><script>self.__next_f.push([1,"d:[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/921d4336bf7f3963.js\",\"async\":true,\"nonce\":\"$undefined\"}]\ne:[\"$\",\"script\",\"script-1\",{\"src\":\"/_next/static/chunks/08151fe5d8ff984c.js\",\"async\":true,\"nonce\":\"$undefined\"}]\nf:[\"$\",\"$L1f\",null,{\"children\":[\"$\",\"$20\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@21\"}]}]\n10:[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L22\",null,{\"children\":\"$L23\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$L24\",null,{\"children\":[\"$\",\"$20\",null,{\"name\":\"Next.Metadata\",\"children\":\"$L25\"}]}]}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]\n"])</script><script>self.__next_f.push([1,"13:[\"$\",\"div\",null,{\"className\":\"overflow-hidden rounded-t-lg bg-muted\",\"children\":[\"$\",\"$L12\",null,{\"src\":\"/placeholder.svg\",\"alt\":\"Workflow for underwater AI systems\",\"width\":640,\"height\":240,\"className\":\"h-24 w-full object-cover\"}]}]\n14:[\"$\",\"div\",null,{\"data-slot\":\"card-content\",\"className\":\"p-5\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"mb-3 text-lg font-semibold\",\"children\":\"How\"}],[\"$\",\"ul\",null,{\"className\":\"list-disc space-y-2 pl-4 text-sm text-muted-foreground\",\"children\":[[\"$\",\"li\",null,{\"children\":\"Develop customized ROVs with multi-sensor capabilities.\"}],[\"$\",\"li\",null,{\"children\":\"Train Vision-Language Models (VLMs) for underwater perception.\"}],[\"$\",\"li\",null,{\"children\":\"Enable robotic swarms for wide-area coverage and cooperative decision-making.\"}],[\"$\",\"li\",null,{\"children\":\"Build multi-modal analytics for underwater data integration and interpretation.\"}],[\"$\",\"li\",null,{\"children\":\"Validate through simulation, lab, and real-world testing.\"}]]}]]}]\n15:[\"$\",\"rect\",\"4q2zg0\",{\"x\":\"16\",\"y\":\"16\",\"width\":\"6\",\"height\":\"6\",\"rx\":\"1\"}]\n16:[\"$\",\"rect\",\"8cvhb9\",{\"x\":\"2\",\"y\":\"16\",\"width\":\"6\",\"height\":\"6\",\"rx\":\"1\"}]\n17:[\"$\",\"rect\",\"1egb70\",{\"x\":\"9\",\"y\":\"2\",\"width\":\"6\",\"height\":\"6\",\"rx\":\"1\"}]\n18:[\"$\",\"path\",\"1jsf9p\",{\"d\":\"M5 16v-3a1 1 0 0 1 1-1h12a1 1 0 0 1 1 1v3\"}]\n19:[\"$\",\"path\",\"2874zd\",{\"d\":\"M12 12V8\"}]\n1a:[\"$\",\"h3\",null,{\"className\":\"mb-2 text-xl font-semibold\",\"children\":\"Multi-Robot Coordination\"}]\n1b:[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground leading-relaxed\",\"children\":\"Decision-making algorithms for coordinating multiple AUVs in complex marine environments.\"}]\n1c:[\"$\",\"div\",null,{\"data-slot\":\"card\",\"className\":\"bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm border-border/50 transition-shadow hover:shadow-lg\",\"children\":[\"$\",\"div\",null,{\"data-slot\":\"card-content\",\"className\":\"p-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-4 flex h-12 w-12 items-center justify-center rounded-lg bg-chart-2/10\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-microscope h-6 w-6 text-chart-2\",\"children\":[[\"$\",\"path\",\"1borvv\",{\"d\":\"M6 18h8\"}],[\"$\",\"path\",\"8prr45\",{\"d\":\"M3 22h18\"}],[\"$\",\"path\",\"1jwaiy\",{\"d\":\"M14 22a7 7 0 1 0 0-14h-1\"}],[\"$\",\"path\",\"197e7h\",{\"d\":\"M9 14h2\"}],[\"$\",\"path\",\"1bmzmy\",{\"d\":\"M9 12a2 2 0 0 1-2-2V6h6v4a2 2 0 0 1-2 2Z\"}],[\"$\",\"path\",\"1drr47\",{\"d\":\"M12 6V3a1 1 0 0 0-1-1H9a1 1 0 0 0-1 1v3\"}],\"$undefined\"]}]}],[\"$\",\"h3\",null,{\"className\":\"mb-2 text-xl font-semibold\",\"children\":\"Testing \u0026 Validation\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground leading-relaxed\",\"children\":\"Comprehensive validation from simulation to real-world marine scenarios ensuring robust performance.\"}]]}]}]\n1d:[\"$\",\"div\",null,{\"data-slot\":\"card\",\"className\":\"bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm border-border/50 transition-shadow hover:shadow-lg\",\"children\":[\"$\",\"div\",null,{\"data-slot\":\"card-content\",\"className\":\"p-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-4 flex h-12 w-12 items-center justify-center rounded-lg bg-chart-3/10\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-database h-6 w-6 text-chart-3\",\"children\":[[\"$\",\"ellipse\",\"msslwz\",{\"cx\":\"12\",\"cy\":\"5\",\"rx\":\"9\",\"ry\":\"3\"}],[\"$\",\"path\",\"1wlel7\",{\"d\":\"M3 5V19A9 3 0 0 0 21 19V5\"}],[\"$\",\"path\",\"mv7ke4\",{\"d\":\"M3 12A9 3 0 0 0 21 12\"}],\"$undefined\"]}]}],[\"$\",\"h3\",null,{\"className\":\"mb-2 text-xl font-semibold\",\"children\":\"Open Research\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground leading-relaxed\",\"children\":\"Publishing findings, presenting at conferences, and engaging with the scientific community.\"}]]}]}]\n"])</script><script>self.__next_f.push([1,"1e:[\"$\",\"div\",null,{\"data-slot\":\"card\",\"className\":\"text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm border-border/50 bg-accent/15 transition-shadow hover:shadow-lg\",\"children\":[\"$\",\"div\",null,{\"data-slot\":\"card-content\",\"className\":\"p-6\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"mb-2 text-xl font-semibold\",\"children\":\"Explore More\"}],[\"$\",\"p\",null,{\"className\":\"mb-4 text-sm text-muted-foreground leading-relaxed\",\"children\":\"Discover detailed information about each work package, timeline, and research outputs.\"}],[\"$\",\"$L7\",null,{\"href\":\"/work-packages\",\"children\":[\"View All Work Packages\",[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-arrow-right ml-2 h-4 w-4\",\"children\":[[\"$\",\"path\",\"1ays0h\",{\"d\":\"M5 12h14\"}],[\"$\",\"path\",\"xquz4c\",{\"d\":\"m12 5 7 7-7 7\"}],\"$undefined\"]}]],\"data-slot\":\"button\",\"className\":\"inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [\u0026_svg]:pointer-events-none [\u0026_svg:not([class*='size-'])]:size-4 shrink-0 [\u0026_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 h-8 rounded-md gap-1.5 px-3 has-[\u003esvg]:px-2.5\",\"ref\":null}]]}]}]\n"])</script><script>self.__next_f.push([1,"23:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"21:null\n25:[[\"$\",\"title\",\"0\",{\"children\":\"RoboGenAI | Underwater Robotics \u0026 AI for Marine Exploration\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Integration of Generative AI and Vision Language Models in Underwater Robotic Systems for Marine Exploration and Monitoring\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"RoboGenAI Consortium\"}],[\"$\",\"meta\",\"3\",{\"name\":\"keywords\",\"content\":\"underwater robotics,generative AI,vision language models,marine exploration,ROV,autonomous systems\"}]]\n"])</script></body></html>